\documentclass[mirror, portugues]{revdetua}

% Valid options are:
%   portugues --------- main language is Portuguese
%   final ------------- final version (default)
%   times ------------- use times (postscript) fonts for text
%   mirror ------------ prints a mirror image of the paper (with dvips)
%   visiblelabels ----- \SL, \SN, \SP, \EL, \EN, etc. defined
%   invisiblelabels --- \SL, \SN, \SP, \EL, \EN, etc. not defined (default)
%
% Note: the final version should use the times fonts
% Note: the really final version should also use the mirror option

\usepackage[portuguese]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath} 
\usepackage{comment}
\usepackage{algorithm}
\usepackage{algpseudocode}
\floatname{algorithm}{Algoritmo}
\usepackage{graphicx}
\usepackage[justification=centering]{caption}
\usepackage{float}
\usepackage{booktabs}
\usepackage[table,xcdraw]{xcolor}
%-------------------------------------
% compiling:
% Recipe: xelatex
% Recipe: pdflatex -> bibtex -> pdflatex -> pdflatex
% Recipe: xelatex
%
% notas:
% rever se algoritmos e imagens estão onde devem
%-------------------------------------
\begin{document}

\Header{03}{3}{Janeiro}{2025}{1}

\title{TITULO DO TRABALHO}
\author{Hugo Veríssimo - 124348 - hugoverissimo@ua.pt}
\maketitle

\begin{abstract}
abstrato em ingles
\end{abstract}

\begin{resumo}
abstrato em pt resumo
\end{resumo}


\section{Introdução}

A análise de texto é uma área de estudo fundamental, com diversas aplicações tais como análise de sentimentos ou de opiniões, personalização da experiência do utilizador, recomendação de conteúdo, entre outras \cite{AZ24}. Uma das tarefas centrais nesta área é a identificação da frequência de palavras em grandes volumes de texto, tal como livros, bases de dados ou redes sociais, de modo extrair informações relevantes sobre o conteúdo e estrutura dos textos em análise.

Contudo, a identificação precisa da frequência de palavras em textos de larga escala apresenta desafios significativos, especialmente em termos de memória. Métodos de contagem precisa, que mantêm o registo exato da contagem de cada palavra, revelam-se ineficientes devido ao elevado consumo de memória. Há assim a necessidade do estudo de métodos mais eficientes e escaláveis, principalmente em situações em que os dados estão em constante fluxo, como em \textit{streams} de dados. Neste contexto, algoritmos de contagem aproximada e identificação de itens frequentes têm vindo a ganhar destaque, uma vez que permitem a identificação de palavras mais frequentes de forma eficiente e com uma margem de erro controlada \cite{LH06}.

Este relatório visa explorar três abordagens para este problema: contadores exatos, contadores aproximados e identificação de itens frequentes em \textit{streams} de dados. Para cada uma destas abordagens, será apresentado um algoritmo e .....


%Além da implementação dessas abordagens, será realizada uma análise sobre a eficiência computacional de cada uma delas, considerando o tempo de execução e o uso de memória, bem como suas limitações em termos de precisão e aplicabilidade em diferentes cenários. O objetivo é entender as trade-offs entre precisão e eficiência e fornecer uma base para a escolha do método mais adequado para diferentes tipos de dados e requisitos de processamento. CHATICEGERONIMOPORTUGALTIAGO


\section{Metodologia da Análise}

Para realizar a análise de frequência de palavras, foram selecionados três livros, a partir livraria online \textit{Project Gutenberg} \cite{PG24}, nomeadamente: \textit{Pinocchio: The Tale of a Puppet} (em inglês, EN), \textit{Le avventure di Pinocchio: Storia di un burattino} (em italiano, IT) e \textit{Pinocchion seikkailut: Kertomus marioneteista} (em finlandês, FI). Estes livros foram selecionados por serem traduções do mesmo livro original, conhecido em português como \textit{As Aventuras de Pinóquio}, de Carlo Collodi. A escolha destes livros permite a comparação da frequência de palavras em diferentes idiomas, bem como a análise de semelhanças e diferenças entre as traduções.

Numa primeira fase, os ficheiros de texto descarregados a partir do \textit{Project Gutenberg} foram processados removendo informações irrelevantes, como metadados e licenças, palavras insignificantes e sinais de pontuação. Para além disso todas as palavras foram convertidas para minúsculas e lematizadas. Estas transformações são fundamentais, de modo a simplificar o texto e concentrar a análise nas palavras mais relevantes, garantindo uma avaliação mais precisa e eficiente da frequência de termos. É importante referir que estas transformações foram realizadas com recurso à biblioteca \textit{spaCy}, através do \textit{Python}.


implementar algortimos, analise dos dados, correr ns quantas vezes, .....


\section{Contadores Exatos}

Quanto aos contadores exatos, tal como o nome indica, este tipo de técnica é exate, resultando numa contagem precisa da frequência de palavras, no contexto em causa.
O algoritmo apresentado de seguida, designado por \textit{Contador Exato}, é um exemplo de um contador exato, que percorre o texto processado e regista a frequência de cada palavra num dicionário. Este algoritmo é eficiente em termos de precisão, uma vez que mantém um registo exato da contagem de cada palavra, no entanto, revela-se ineficiente em termos de memória, especialmente em situações em que o volume de texto é elevado.

\begin{algorithm}[H]
\raggedright
\textbf{Entrada:} texto processado (\texttt{T}) \\
\textbf{Saída:} dicionário onde as palavras são as chaves e os valores são as suas frequências (\texttt{D})\\
\hrule 
\caption{Contador Exato}
\begin{algorithmic}[1]
    \State \texttt{D} $\gets$ empty dictionary
    \State \texttt{words} $\gets$ list of words from \texttt{T}
    \For{each \texttt{word} in \texttt{words}}
        \If{\texttt{word} $\not\in$ \texttt{D}}
            \State \texttt{D}[\texttt{word}] $\gets$ 0
        \EndIf
        \State \texttt{D}[\texttt{word}] $\gets$ \texttt{D}[\texttt{word}] + $1$
    \EndFor
    \State \Return \texttt{D}
\end{algorithmic}
\end{algorithm}
    
Atendendo à complexidade espacial, no pior caso, onde todas as palavras que constituem o texto \texttt{T} são distintas, a mesma é dada por $O(|\texttt{words}|)$, onde $|\texttt{words}|$ representa o número de palavras no texto. Isto acontece pelo facto do dicionário \texttt{D} conter uma entrada para cada palavra distinta no texto. NAO SEI SE ESTA CERTO, NS SE TENHO DE CONTABILIZAR O TAMANHO DE WORDS AO EM INVES DE SER SO O D ou REFERIR QUE O QUE IMPORTA É O TAMANHO DO DICIONARIO? TALVEZ FALAR DOS DOIS e dps no fim dizer q o words deve ser ignorado pq é o texto e o que importa é o dicionario? idk

comparison of the memory (complexity ?) of the algorithms

.....

através da aplicacao do algoritmo de contagem exata, foi possível identificar as 10 palavras mais frequentes em cada um dos livros analisados. A Tabela \ref{table:top10_exatos} apresenta as palavras mais frequentes em cada idioma, juntamente com o número de ocorrências de cada palavra.

\begin{table}[H]
\centering
\caption{CAPTION top10 palavras mais frequentes em cada idioma}
\label{table:top10_exatos}
\begin{tabular}{lr|lr|lr}
\toprule
\multicolumn{2}{c}{EN} & \multicolumn{2}{c}{IT} & \multicolumn{2}{c}{FI} \\
Palavra & \# & Palavra & \# & Palavra & \# \\
\midrule
pinocchio & 457 & pinocchio & 460 & pinocchio & 443 \\
say & 282 & il & 386 & sanoa & 258 \\
little & 238 & dire & 282 & saada & 143 \\
puppet & 209 & si & 251 & alkaa & 134 \\
come & 141 & burattino & 225 & tehdä & 134 \\
boy & 140 & volere & 167 & marionetti & 131 \\
like & 133 & vedere & 152 & poika & 81 \\
good & 131 & andare & 134 & huutaa & 81 \\
poor & 127 & povero & 134 & nähdä & 80 \\
go & 116 & ragazzo & 126 & kysyä & 77 \\
\bottomrule
\end{tabular}
\end{table}


como seria de esperar, a palavra "pinocchio" é a mais frequente em todos os idiomas, uma vez que se trata do nome do protagonista do livro. Para além disso, é possível observar algumas semelhanças entre os idiomas, nomeadamente a presença de palavras que têm o mesmo siginificado em diferentes idiomas, como "puppet" e "burattino" (marioneta em italiano), ...

para além disso, esta analise tambem permite a analise da quantidade de palavras distintas Fig. \ref{fig:distinc_words} em cada idioma, bem como a distribuição da frequência de palavras Fig. \ref{fig:word_freqs}, o que pode ser útil para a comparação de diferentes traduções de um mesmo livro, por exemplo.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{../assets/exact_word_freqs.png}
    \caption{distribuicao da frequência de palavras em cada idioma}
    \label{fig:word_freqs}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{../assets/exact_distinct_words.png}
    \caption{numero de palavras distintas em cada idioma}
    \label{fig:distinc_words}
\end{figure}

a diferenca pode ter a ver com o desempenho do spacy a lematizar as palavras em diferentes idiomas, ou com a propria complexidade da lingua 






\section{Contadores Aproximados}

Os contadores aproximados, também conhecidos por contadores probabilísticos, inventados por Robert Morris, são algoritmos especializados em realizar estimativas eficientes de contagens, utilizando quantidades reduzidas de memória em comparação com métodos tradicionais, através de técnicas baseadas em probabilidade. Estes contadores são particularmente úteis em situações em que a precisão exata da contagem não é crítica, permitindo uma redução significativa no uso de memória, sem comprometer a qualidade da análise \cite{RM78}.

Um exemplo de um contador aproximado é o algoritmo de contagem aproximada apresentado de seguida, designado por \textit{Contador Aproximado}. Neste exemplo, o algoritmo utiliza uma probabilidade de contagem fixa de $1/16$. Para cada evento, neste caso, cada palavra do texto, é gerado um número aleatório entre 0 e 1, e a palavra é contada se o número gerado for menor que a probabilidade de contagem. Isto permite que a contagem seja realizada de forma aproximada, com uma margem de erro controlada, e um menor uso de memória.

\begin{algorithm}[H]
\raggedright
\textbf{Entrada:} texto processado (\texttt{T}) \\
\textbf{Saída:} dicionário onde as palavras são as chaves e os valores são as suas frequências estimadas (\texttt{D})\\
\hrule 
\caption{Contador Aproximado}
\begin{algorithmic}[1]
    \State \texttt{D} $\gets$ empty dictionary
    \State \texttt{words} $\gets$ list of words from \texttt{T}
    \For{each \texttt{word} in \texttt{words}}
    \State \texttt{r} $\gets$ Uniform(0, 1)
    \If{$r < \frac{1}{16}$}
        \If{\texttt{word} $\not\in$ \texttt{D}}
            \State \texttt{D}[\texttt{word}] $\gets$ 0
        \EndIf
        \State \texttt{D}[\texttt{word}] $\gets$ \texttt{D}[\texttt{word}] + $1$
    \EndIf
    \EndFor
    \For{each \texttt{word} in \texttt{D}} \Comment{Estimate the total count}
    \State \texttt{D}[\texttt{word}] $\gets$ \texttt{D}[\texttt{word}] $\times 16$
    \EndFor
    \State \Return \texttt{D}
\end{algorithmic}
\end{algorithm}

é importante referir q existem outros tipos, diferentes fixed probability, etc.

as contagem sao smp multiplas de 16, pq a probabilidade é 1/16, e dps é multiplicado por 16 para obter a contagem aproximada

complexidade espacial tal tal bla bla

nas tabelas seguintes, por ser um processo aleatorio, apos tere sudo corrido 20 vezes, foi calculada a média, valor max e min de cada palavra, escolhidos as 10 mais frequentes tendo em conta a media, e comparado com a contagem exata. nas tabelas seguintes pode-se observar esses resultados, para cada um dos idiomas analisados. também se repara que as palavras a preto mantiiveram a sua posucao em relacao ao top10 exato, as a laranja estao descoladas mas fazem parte, e as a vermelho não fazem parte do top10 real

\begin{table}[H]
\centering
\caption{top10 dos aproximados sendo o top tendo em conta a media, e media arredondada ao inteiro, e idioma ING}
\label{table:top10_aprox_ingles}
\begin{tabular}{lrrr|r}
\toprule
Palavra & $\text{\#}_{\text{médio}}$ & $\text{\#}_{\text{max}}$ & $\text{\#}_{\text{min}}$ & $\text{\#}_{\text{real}}$ \\
\midrule
pinocchio & 439 & 544 & 336 & 457 \\
say & 270 & 400 & 96 & 282 \\
little & 227 & 320 & 144 & 238 \\
puppet & 223 & 336 & 128 & 209 \\
come & 148 & 240 & 64 & 141 \\
boy & 140 & 176 & 80 & 140 \\
\textcolor{orange}{go} & 132 & 240 & 48 & 116 \\
\textcolor{orange}{poor} & 129 & 240 & 48 & 127 \\
\textcolor{orange}{like} & 128 & 192 & 32 & 133 \\
\textcolor{orange}{good} & 126 & 224 & 64 & 131 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{top10 dos aproximados sendo o top tendo em conta a media, e media arredondada ao inteiro, e idioma italiano}
\label{table:top10_aprox_italiano}
\begin{tabular}{lrrr|r}
\toprule
Palavra & $\text{\#}_{\text{médio}}$ & $\text{\#}_{\text{max}}$ & $\text{\#}_{\text{min}}$ & $\text{\#}_{\text{real}}$ \\
\midrule
pinocchio & 439 & 544 & 240 & 460 \\
il & 379 & 512 & 224 & 386 \\
dire & 263 & 448 & 160 & 282 \\
si & 252 & 320 & 128 & 251 \\
burattino & 223 & 320 & 96 & 225 \\
volere & 169 & 256 & 96 & 167 \\
\textcolor{orange}{povero} & 139 & 240 & 32 & 134 \\
\textcolor{red}{bello} & 133 & 240 & 80 & 116 \\
\textcolor{orange}{vedere} & 131 & 192 & 32 & 152 \\
\textcolor{orange}{andare} & 127 & 192 & 80 & 134 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{top10 dos aproximados sendo o top tendo em conta a media, e media arredondada ao inteiro, e idioma finlandes}
\label{table:top10_aprox_finlandes}
\begin{tabular}{lrrr|r}
\toprule
Palavra & $\text{\#}_{\text{médio}}$ & $\text{\#}_{\text{max}}$ & $\text{\#}_{\text{min}}$ & $\text{\#}_{\text{real}}$ \\
\midrule
pinocchio & 445 & 672 & 320 & 443\\
sanoa & 266 & 352 & 160 & 258 \\
saada & 160 & 256 & 48 & 143 \\
\textcolor{orange}{tehdä} & 136 & 224 & 48 & 134 \\
\textcolor{orange}{marionetti} & 132 & 224 & 80 & 131 \\
\textcolor{orange}{alkaa} & 104 & 160 & 64 & 134 \\
\textcolor{red}{geppetto} & 87 & 160 & 32 & 71 \\
huutaa & 86 & 128 & 32 & 81 \\
\textcolor{red}{pää} & 80 & 128 & 32 & 65 \\
\textcolor{red}{olla} & 76 & 144 & 16 & 61 \\
\bottomrule
\end{tabular}
\end{table}

nota se mais erros quanto menor é a contagem, pq ha maior densidade de palavras, como se viu na contagem exata figura tal


\section{Contadores Space-Saving}

Pelo facto de muitos processos de geração de dados poderem ser modelados como fluxos de dados, que produzem enormes quantidades de informações simples isoladamente, mas que, em conjunto, formam um todo complexo, torna-se interessante a utilização de métodos que respondam rapidamente a cada nova informação e utilizem recursos muito pequenos em comparação com o volume total de dados. Neste contexto, o algoritmo de contagem \textit{Space-Saving} é uma solução eficiente para a identificação de itens frequentes em \textit{streams} de dados, permitindo acompanhar contagens frequentes de forma eficiente, mesmo sob restrições de memória \cite{CG09}.

Este algoritmo é exposto no pseudocódigo seguinte:

\begin{algorithm}[H]
\raggedright
\textbf{Entrada:} \\
- texto processado (\texttt{T}) \\
- número máximo de itens a manter (\texttt{k}) \\
\textbf{Saída:} dicionário com a estimativa das \texttt{k} palavras mais frequentes e respetivas frequências estimadas (\texttt{D}) \\
\hrule 
\caption{Contador \textit{Space-Saving} \cite{CG09}}
\begin{algorithmic}[1]
    \State \texttt{D} $\gets$ empty dictionary
    \State \texttt{words} $\gets$ list of words from \texttt{T}
    \For{each \texttt{word} in \texttt{words}}
        \If{\texttt{word} $\in$ \texttt{D}}
            \State \texttt{D}[\texttt{word}] $\gets$ \texttt{D}[\texttt{word}] + $1$
        \ElsIf{$|\texttt{D}| < \texttt{k}$}
            \State \texttt{D}[\texttt{word}] $\gets$ $1$
        \Else
            \State \texttt{j} $\gets$ $\arg \min_{j \in \texttt{D}}\ \texttt{D}[\texttt{j}]$
            \State \texttt{D}[\texttt{word}] $\gets$ \texttt{D}[\texttt{j}] + $1$
            \State \texttt{D} $\gets$ \texttt{D} $\setminus \{\texttt{j}\}$
        \EndIf
    \EndFor
    \State \Return \texttt{D}
\end{algorithmic}
\end{algorithm}

dizer limitacoes

apresentar resultados

....


\section{Resultados}

ou comparacao dos metodos ou assim




\section{Conclusão}

conclusaoooo

\bibliography{refs}

\end{document}
