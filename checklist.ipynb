{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO, para alem do q esta em baixo\n",
    "\n",
    "- Ã© ok lemmatizar as palavras? SIM\n",
    "\n",
    "- space saving precisa de pelo menos 80 para ter um bom resultado... OK N FAZ MAL\n",
    "\n",
    "- NAO TE PREOCUPES TANTO COM COMPLEXIDADE ESPACIAL, TENS DE TER MAIS EM CONTA OS BYTES... talvez fazer analise de bytes dentro de cada seccao e dps no fim fazer uma tabela \n",
    "\n",
    "- aa - ver erros e isso nos resultados das contagens, de forma quantificada e grafica se der\n",
    "\n",
    "- tabela: meter min, media, max em vez de ser media primeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gutenberg.org/ebooks/52484 : italian\n",
    "\n",
    "https://www.gutenberg.org/ebooks/53077 : finnish\n",
    "\n",
    "https://www.gutenberg.org/ebooks/16865 : english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adicionar ao guide total de palavras diferentes por texto, se quiseres fazer algo extra\n",
    "\n",
    "- approaches\n",
    "\n",
    "    - one algorithm to identify frequent items in data streams (n most frequent words, eg. e.g., 5, 10, 15, 20)\n",
    "\n",
    "- analysis of the computational efficiency and limitations of the developed approaches ()\n",
    "\n",
    "    - comparison of the memory (complexity ?) of the algorithms\n",
    "\n",
    "    - absolute and relative errors (lowest value, highest value, average value, etc.)\n",
    "\n",
    "    - evaluate the quality of estimates\n",
    "\n",
    "    - same most frequent / less frequent words are identified, and in the same relative order\n",
    "\n",
    "    - most frequent / less frequent words are similar in the text files of the same book in different language\n",
    "\n",
    "    - Compare the performance between themselves and regarding the exact counts.\n",
    "\n",
    "~~- etc.~~\n",
    "\n",
    "~~- approximate counters (repeating the approximate counts a few times.)~~\n",
    "\n",
    "~~- identify frequent words in text files (books)~~\n",
    "\n",
    "~~- aa tabela: top X words: word, exact count, prob counter, stresm count, pintar palavras erradas e dentro do prob: mean, min, max PQ e preciso correr mts vezes~~\n",
    "\n",
    "~~- exact counters, (exact number of occurrences of each word.)~~\n",
    "\n",
    "~~- 3 a 4 livros em diferentes linguas~~\n",
    "\n",
    "~~- Remove the Project Gutenberg file header and file tail,~~\n",
    "\n",
    "~~- Remove all stop-words and punctuation marks.~~\n",
    "\n",
    "~~- Convert all letters to lowercase.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
